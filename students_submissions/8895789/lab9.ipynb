{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAB_9 - Dense Neural Network\n",
    "### Name: Ramya Chandran\n",
    "### StudenID: 8895789"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Using Keras Datasets, obtain the fMNIST data set. Explore and describe it as you would do with any new dataset that you start working with (2 points). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-21 22:50:16.993772: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fMNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "# Check the number of samples and dimensions\n",
    "print(\"Number of training samples:\", train_images.shape[0])\n",
    "print(\"Number of test samples:\", test_images.shape[0])\n",
    "print(\"Image dimensions:\", train_images.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of classes and their corresponding labels\n",
    "classes = np.unique(train_labels)\n",
    "print(\"Classes:\", classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some sample images from the training set\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.imshow(train_images[i], cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exploration of the fMNIST dataset provides an initial understanding of its size, class distribution, and visual appearance. It contains grayscale images of various fashion items, and each class is relatively balanced. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Train a dense neural network using Keras (2 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values to range [0, 1]\n",
    "train_images = train_images.astype('float32') / 255.0\n",
    "test_images = test_images.astype('float32') / 255.0\n",
    "\n",
    "# Flatten the images for the dense neural network\n",
    "train_images = train_images.reshape((60000, 784))\n",
    "test_images = test_images.reshape((10000, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape=(784,)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "batch_size = 32\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=num_epochs,\n",
    "                    batch_size=batch_size, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The activation function used in the hidden layers is ReLU, and for the output layer, we use the softmax activation to obtain class probabilities for multi-class classification.\n",
    "\n",
    "We compile the model using the Adam optimizer and categorical cross-entropy loss, which is suitable for multi-class classification problems. Finally, we train the model on the training data for 10 epochs with a batch size of 32 and use 10% of the training data for validation during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Evaluate its accuracy. Report accuracy, confusion metric, explore specific examples of incorrect classification, and drew some conclusions from this exploration (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(test_images, test_labels)\n",
    "print(\"Test accuracy:\", accuracy)\n",
    "\n",
    "# Predict the test set labels\n",
    "predictions = model.predict(test_images)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(np.argmax(test_labels, axis=1), predicted_labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.arange(10))\n",
    "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Explore some examples of incorrect classifications\n",
    "incorrect_idx = np.where(predicted_labels != np.argmax(test_labels, axis=1))[0]\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, idx in enumerate(incorrect_idx[:25]):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.imshow(test_images[idx], cmap='gray')\n",
    "    plt.title(f\"True: {np.argmax(test_labels[idx])}, Predicted: {predicted_labels[idx]}\")\n",
    "    plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By exploring examples of incorrect classifications, It reveals cases where certain classes are harder to distinguish due to visual similarities, and it may highlight potential areas of improvement, such as the need for more data or better model architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
